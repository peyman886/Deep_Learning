{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "u4_q3YCOjUlc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        " \n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm.notebook import tqdm \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json, os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HC4GVy8Osn6"
      },
      "source": [
        "In this homework, we will explore deep networks using  PyTorch framework!\n",
        "With the MNIST dataset consisting of 70000 images (28 * 28 * 1) of handwritten digits, we will train a multiple-layer perceptron network to detect the digit corresponding to the input image. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ],
      "metadata": {
        "id": "n1ul5xRbZysL",
        "outputId": "88221562-3332-4538-ce32-16e57dc0709f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zeodqY-UL9t"
      },
      "source": [
        "#Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NIB1N86T4vP"
      },
      "source": [
        "Run the cell below to download the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "JE6t9NG3XcnB",
        "outputId": "ca5cc521-32f7-4537-ad26-b2479179582f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-356f6071bbfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m mnist_train = datasets.MNIST(root='./data', train=True, download=True,\n\u001b[1;32m      3\u001b[0m                              \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                              ,target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)))\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Lambda'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import ambda\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, download=True,\n",
        "                             transform=transforms.ToTensor()\n",
        "                             ,target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)))\n",
        "\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True,transform=transforms.ToTensor()) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "vfqms4_IjlmL",
        "outputId": "11955f2f-1521-49aa-cac6-fde6cdf43564",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "mnist_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "Qw8tVtRe5St_",
        "outputId": "061dbd65-685a-483a-8010-c4ba3aafe2b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: ./data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "mnist_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "qSVexjkV6OX5",
        "outputId": "ba6ac0f3-0248-4754-9578-25078df656f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "image, label = mnist_test[0]\n",
        "label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "F4l05jpAUDdH",
        "outputId": "76ea2fb9-ce55-416a-93ab-09c46494c8e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "mGYK9gIi6TcS",
        "outputId": "8c85f9a0-4a96-4a3e-ca66-d8a368f242dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2625214460>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(image.reshape(28,28), cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5-BCDKAV0RV"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZauc_yJV7l7"
      },
      "source": [
        "\n",
        "The model we want to classify the MNIST dataset is a two-hidden-layer MLP with 120 and 84 units in each layer, respectively. \n",
        "\n",
        "Create a PyTorch model for described model and use ReLU for the activation function.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "dTOrHU2s7ww6"
      },
      "outputs": [],
      "source": [
        "class MultilayerPerceptron(nn.Module):\n",
        "  def __init__(self, act_fn=nn.ReLU(), input_size=784, num_classes=10, hidden_sizes=[512, 256, 256, 128]):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "      act_fn - Object of the activation function that should be used as non-linearity in the network.\n",
        "      input_size - Size of the input images in pixels\n",
        "      num_classes - Number of classes we want to predict\n",
        "      hidden_sizes - A list of integers specifying the hidden layer sizes in the NN\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    \n",
        "    # Create the network based on the specified hidden sizes\n",
        "    layers = []\n",
        "    layer_sizes = [input_size] + hidden_sizes\n",
        "    for layer_index in range(1, len(layer_sizes)):\n",
        "        layers += [nn.Linear(layer_sizes[layer_index-1], layer_sizes[layer_index]),\n",
        "                    act_fn]\n",
        "    layers += [nn.Linear(layer_sizes[-1], num_classes), nn.LogSoftmax(dim=1)]\n",
        "    self.layers = nn.ModuleList(layers) # A module list registers a list of modules as submodules (e.g. for parameters)\n",
        "    \n",
        "    self.config = {\"act_fn\": act_fn.__class__.__name__, \"input_size\": input_size, \"num_classes\": num_classes, \"hidden_sizes\": hidden_sizes} \n",
        "    \n",
        "\n",
        "  def forward(self, x):\n",
        "    # Perform the calculation of the model to determine the prediction\n",
        "    x = x.view(x.size(0), -1)\n",
        "    for l in self.layers:\n",
        "      x = l(x)\n",
        "    return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "C8lVcUidYxZR",
        "outputId": "cf51853a-8cbb-4cbf-ea8a-0ef82b45fb92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultilayerPerceptron(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=120, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
              "    (5): LogSoftmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "torch.manual_seed(80)\n",
        "model = MultilayerPerceptron(hidden_sizes=[120, 84])\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!brew install graphviz\n",
        "!pip install torchviz"
      ],
      "metadata": {
        "id": "9VqxZahNWgRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchviz import make_dot\n",
        "# batch = next(iter(dataloader_train))\n",
        "# yhat = model(batch.text) # Give dummy batch to forward().\n",
        "# make_dot(yhat, params=dict(list(model.named_parameters()))).render(\"rnn_torchviz\", format=\"png\")"
      ],
      "metadata": {
        "id": "3wtFjUKmWn4m"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHCtONg8LbYU"
      },
      "source": [
        "Answer these questions:\n",
        "2. Denote the size of the weights matrix of each layer (consider the input and output layer as well). \n",
        "1. What initial values are used  ​​for the weights and biases of your model? (Do not report the specific value, we are interested in distributions that are used.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWv1_hwjkq4j"
      },
      "source": [
        "#Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLbpRcjokxUb"
      },
      "source": [
        "In this section, we want to train our MLP model using the SGD algorithm. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUmhmB0EG7KJ"
      },
      "source": [
        "As we discussed in class, instead of calculating loss using the whole inputs, we break the dataset (with size $n$) into some batches of size m ($m < n$) and, at each iteration, calculate the loss of one batch and update the weights.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XV7HFbxUa-v"
      },
      "source": [
        "Using the `DataLoader` class of the torch library, complete the cell below to batch the test and train dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "Drvm3GNL7eTd"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-sIe-gSF3VY"
      },
      "source": [
        "there are yet a couple of hyperprameters that we should define before training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "_u-Vzy9zURKD"
      },
      "outputs": [],
      "source": [
        "\n",
        "epochs = 10\n",
        "learning_rate = 0.01 #feel free to play with this\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TI9B7UQ1hu8"
      },
      "source": [
        "Answer these questions:\n",
        "* Prove that the **expected value** of the gradient obtained using a random batch equals the gradient of the whole dataset.\n",
        "\n",
        "* For the dataset of size $n = $12000, if the batch size is 200, what would be the number of weight updates (or iterations) in a total of 5 epoche?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRCAmupNPnRK"
      },
      "source": [
        "\n",
        "Complete the training function below, such that at each epoch:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1. For each batch:\n",
        "\n",
        "  1. Perform feedforward\n",
        "  2. Calculate loss (use cross-entropy loss)\n",
        "  3. Perform backpropagation and updating weights\n",
        "\n",
        "2. Calculate and report the training accuracy and loss for each epoch (use the average of the batch accuracy as epoch accuracy).\n",
        "3. Calculate and report the test accuracy and loss for each epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "toDAqJnr73Ne"
      },
      "outputs": [],
      "source": [
        "#initialize loss function and optimizer\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Push model to device. Has to be only done once\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "i95RpkQHZiaY",
        "outputId": "f5ccc6a6-a007-4d13-b0d0-a12e71e1e1d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultilayerPerceptron(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=120, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
              "    (5): LogSoftmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6cNtYZS8o72"
      },
      "source": [
        "Highly encourage you to use [this](https://github.com/tqdm/tqdm) awesome package called taqaddum to have a nice progress bar for the training process\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "dIj4OrwYE7Hn"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(model, loss_function, optimizer, train_loader, test_loader, epochs):\n",
        "  train_losses = []\n",
        "  test_losses = []\n",
        "  train_acc = []\n",
        "  test_acc  = []\n",
        "\n",
        "  \n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    # Set model to train mode\n",
        "    # Training loop\n",
        "    model.train() \n",
        "    true_preds, count = 0., 0\n",
        "    epoch_loss = 0.0\n",
        "    # targets = targets.type(torch.LongTensor)\n",
        "    for data_inputs, data_labels in train_loader:\n",
        "        \n",
        "      ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
        "      data_inputs = data_inputs.to(device)\n",
        "      data_labels = data_labels.to(device)\n",
        "      \n",
        "      ## Step 2: Run the model on the input data\n",
        "      preds = model(data_inputs.view(len(data_inputs),-1))\n",
        "      # print(preds[0])\n",
        "\n",
        "      preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
        "      \n",
        "      ## Step 3: Calculate the loss\n",
        "      # print(data_labels )\n",
        "      # print(preds[0])\n",
        "\n",
        "      loss = loss_function(preds, data_labels)\n",
        "      \n",
        "      ## Step 4: Perform backpropagation\n",
        "      # Before calculating the gradients, we need to ensure that they are all zero. \n",
        "      # The gradients would not be overwritten, but actually added to the existing ones.\n",
        "      optimizer.zero_grad() \n",
        "      # Perform backpropagation\n",
        "      loss.backward()\n",
        "      \n",
        "      ## Step 5: Update the parameters\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "      epoch_loss+=loss.item()\n",
        "      true_preds += (preds.argmax(dim=-1) == data_labels).sum().item()\n",
        "      count += data_labels.shape[0]\n",
        "    train_losses.append(loss.item()/len(data_inputs))\n",
        "    t_acc = true_preds / count\n",
        "    train_acc.append(t_acc)\n",
        "\n",
        "    model.eval()\n",
        "    ttrue_preds, count = 0., 0\n",
        "    epoch_loss = 0.0\n",
        "    for data_inputs, data_labels in test_loader:\n",
        "        data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
        "        with torch.no_grad():\n",
        "            preds = model(data_inputs).argmax(dim=-1)\n",
        "            loss = loss_function(preds, data_labels)\n",
        "            epoch_loss+=loss.item()\n",
        "\n",
        "            true_preds += (preds == data_labels).sum().item()\n",
        "            count += data_inputs.shape[0]\n",
        "    test_losses.append(loss.item()/len(data_inputs))\n",
        "    test_acc = true_preds / count\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    #todo\n",
        "\n",
        "\n",
        "\n",
        "    return train_losses, train_acc, test_acc, test_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "ovj6uYbAtm8L",
        "outputId": "fd8f86f7-7f38-451e-c10f-d7864ecfd0c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361,
          "referenced_widgets": [
            "0bde84bb57d64764a9d89f3ef86f8232",
            "7a5e8f06686445a4b74b38d5ca759e1d",
            "6598a8bb43a0433cb97dd050e8a731af",
            "f13b61f52d7d4e0c8b718c6dd29334ef",
            "aa6f897014ea4c2db67d7410ce9bbd01",
            "d38b22c50f3c42d58524d13ce684ee7e",
            "e3f079daf5eb4693866dcc5cdf533cea",
            "53b83854e98b4e92adeff35723431846",
            "65c18bda5fe34a7aa6536f5b7d16ed81",
            "2050701d0d0f49acb34114de3b779e6c",
            "8a4a8ca810fc47ef8cda36de0bd00150"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bde84bb57d64764a9d89f3ef86f8232"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-0cc8ee62349f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-112-17cec01f0d0c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss_function, optimizer, train_loader, test_loader, epochs)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mepoch_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected floating point type for target with class probabilities, got Long"
          ]
        }
      ],
      "source": [
        "train_losses, train_acc, test_acc, test_losses = train(model, loss_function, optimizer, train_loader, test_loader, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BV2NqFdwmUO"
      },
      "source": [
        "Now plot the training results (one plot for test and training accuracy and one for the loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVeoEM7QLHSr"
      },
      "outputs": [],
      "source": [
        "#plot loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tFdIJD-x96y"
      },
      "outputs": [],
      "source": [
        "#plot accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLBY62Fcw4wt"
      },
      "source": [
        "Based on your plots, answer these questions:\n",
        "1. Compare the training and test loss\n",
        "2. Did your model become overfitted? Why?\n",
        "3. Why your training loss is not a  decreasing function with respect to #epoch?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vhuk-mnf2iIn"
      },
      "source": [
        "Repeat the training process for 5 diffrent learning rate and compare the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmMMXJSl2g4h"
      },
      "outputs": [],
      "source": [
        "#to do"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZ5vhsvjyIr7"
      },
      "source": [
        "#Vanishing Gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we want to see the vanishing gradient problem.\n",
        "\n",
        "Create two separate models with 5 hidden layers of size [100, 100, 80, 50, 30],\n",
        "one of them uses ReLU as an activation function and the other one uses Sigmoid.\n"
      ],
      "metadata": {
        "id": "BdqbTH68J5hF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltw-XU-Xy8kY"
      },
      "outputs": [],
      "source": [
        "class MLP_relu(nn.Module):\n",
        "\n",
        "  #todo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP_sigmoid(nn.Module):\n",
        "\n",
        "  #todo\n"
      ],
      "metadata": {
        "id": "F9IL6wQhpg7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiate the models\n"
      ],
      "metadata": {
        "id": "CJw_AgIqqB0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify the train function to save the gradient and weights of each layer, every epoch. Return these values as well. "
      ],
      "metadata": {
        "id": "6yn7GJCIxr8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loss_function, optimizer, train_loader, test_loader, epochs):\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    train_acc = []\n",
        "    test_acc  = []\n",
        "    weights = {'H1':[], 'H2':[], 'H3':[],'H4':[], 'H5':[]}\n",
        "    biases = {'H1':[], 'H2':[], 'H3':[],'H4':[], 'H5':[]}\n",
        "    grads = {'H1':[], 'H2':[], 'H3':[],'H4':[], 'H5':[]}\n",
        "\n",
        "\n",
        "    #todo\n",
        "\n",
        "\n",
        "\n",
        "    return train_losses, train_acc, test_acc, test_losses, weights, grads"
      ],
      "metadata": {
        "id": "owVOfUYjPLei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, train the sigmoid and relu model."
      ],
      "metadata": {
        "id": "XLsPDMyiPKYT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpfTlX_dzUeo"
      },
      "outputs": [],
      "source": [
        "#training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oj0CjH_kzbrt"
      },
      "outputs": [],
      "source": [
        "#plot loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot accuracy"
      ],
      "metadata": {
        "id": "6IA1xaS5QkWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the sigmoid model is not good at all. Based on the following plots explain why."
      ],
      "metadata": {
        "id": "qcyJufaazMzT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each layer, calculate the mean and std (standard deviation) of all its weights and plot these values ​​vs #epochs. Repeat the same for the grads.\n",
        "\n",
        "You should do:\n",
        "\n",
        "* Calculate the average weight of each hidden layer in each epoch.\n",
        "* Calculate the std for the weight of each hidden layer in each epoch.\n",
        "\n",
        "* Calculate the average grads of each hidden layer in each epoch.\n",
        "* Calculate the std for the grads of each hidden layer in each epoch.\n",
        "\n",
        "Plot all of them for both models (use subplot to compare two models' results).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F3wSt4k5znex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calcute means and stds"
      ],
      "metadata": {
        "id": "RGXk99Ht10Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot weights mean for the both models"
      ],
      "metadata": {
        "id": "Vq35DPN41nWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot weights std for the both models"
      ],
      "metadata": {
        "id": "etPX2STS1u9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot grads mean for the both models"
      ],
      "metadata": {
        "id": "zoXOrJYT1xoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot grads std for the both models"
      ],
      "metadata": {
        "id": "tUj9Q65E1x6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good Luck!"
      ],
      "metadata": {
        "id": "s5-2hPa-5Zww"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0bde84bb57d64764a9d89f3ef86f8232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a5e8f06686445a4b74b38d5ca759e1d",
              "IPY_MODEL_6598a8bb43a0433cb97dd050e8a731af",
              "IPY_MODEL_f13b61f52d7d4e0c8b718c6dd29334ef"
            ],
            "layout": "IPY_MODEL_aa6f897014ea4c2db67d7410ce9bbd01"
          }
        },
        "7a5e8f06686445a4b74b38d5ca759e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d38b22c50f3c42d58524d13ce684ee7e",
            "placeholder": "​",
            "style": "IPY_MODEL_e3f079daf5eb4693866dcc5cdf533cea",
            "value": "  0%"
          }
        },
        "6598a8bb43a0433cb97dd050e8a731af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53b83854e98b4e92adeff35723431846",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65c18bda5fe34a7aa6536f5b7d16ed81",
            "value": 0
          }
        },
        "f13b61f52d7d4e0c8b718c6dd29334ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2050701d0d0f49acb34114de3b779e6c",
            "placeholder": "​",
            "style": "IPY_MODEL_8a4a8ca810fc47ef8cda36de0bd00150",
            "value": " 0/10 [00:05&lt;?, ?it/s]"
          }
        },
        "aa6f897014ea4c2db67d7410ce9bbd01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d38b22c50f3c42d58524d13ce684ee7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3f079daf5eb4693866dcc5cdf533cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53b83854e98b4e92adeff35723431846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65c18bda5fe34a7aa6536f5b7d16ed81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2050701d0d0f49acb34114de3b779e6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a4a8ca810fc47ef8cda36de0bd00150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}